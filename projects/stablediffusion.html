<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GenAI Image Generation - Young Woo Song</title>
    <meta name="description" content="Interactive Sketch to Image Tool using Stable Diffusion XL with ControlNet integration for advanced AI-powered image generation">
    <!-- E-ink Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400;500;600;700&family=Space+Mono:wght@400;700&family=Roboto+Mono:wght@300;400;500;600;700&family=Fira+Code:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
        <!-- E-ink Theme Styles -->
    <link rel="stylesheet" href="../css/main-styles.css">
    <link rel="stylesheet" href="../css/project-styles.css">
</head>
<body>
    <!-- Header -->
    <header class="header">
        <div class="container">
            <div class="header-content">
                <a href="../index.html" class="logo">
                    <strong>Y_</strong><span>W_SONG</span>
                </a>
                <nav class="main-nav">
                    <ul class="nav-links">
                        <li><a href="#overview">Overview</a></li>
                        <li><a href="#workflow">Workflow</a></li>
                        <li><a href="#features">Features</a></li>
                        <li><a href="#demo">Demo</a></li>
                        <li><a href="#tools">Tools</a></li>
                    </ul>
                </nav>
                <div class="social-links">
                    <a href="https://github.com/Userdflt" class="social-link" aria-label="GitHub">
                        <i class="fab fa-github"></i>
                    </a>
                    <a href="https://www.linkedin.com/in/young-woo-song-145488217/" class="social-link" aria-label="LinkedIn">
                        <i class="fab fa-linkedin"></i>
                    </a>
                    <a href="https://youngwoosongcv.notion.site/Young-Woo-Song-1c964ba2209280bb954ad884c1a11b0f" class="social-link" aria-label="Resume">
                        <i class="fas fa-file-alt"></i>
                    </a>
                </div>
                <button class="mobile-toggle" aria-label="Menu">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
        </div>
    </header>
    <!-- Project Hero -->
    <section class="project-hero">
        <div class="container">
            <div class="project-hero-content">
                <div class="project-meta">
                    <div class="project-category" data-aos="fade-up" data-aos-delay="400">Generative AI & Image Synthesis</div>
                    <h1 class="project-title" data-aos="fade-up" data-aos-delay="500">GenAI Image Generation</h1>
                    <p data-aos="fade-up" data-aos-delay="600">Sketch-to-Image with Inpainting using Stable Diffusion XL + ControlNet. Turn sketches into photorealistic images and refine them with inpainting â€” all in a local, interactive Tkinter app.</p>
                    <div class="project-links">
                        <a href="https://github.com/Userdflt/InteractiveSketchToRender" class="btn btn-primary" data-aos="fade-up" data-aos-delay="700">
                            <i class="fab fa-github"></i>
                            <span>View Code</span>
                        </a>
                    </div>
                </div>
                <div class="project-hero-image" data-aos="fade-up" data-aos-delay="400">
<img src="../images/stable_sketch.png" alt="Stable Diffusion XL Interface" / class="lazy-image">                </div>
            </div>
        </div>
    </section>
    <!-- Overview Section -->
    <section id="overview" class="project-section" data-aos="fade-up" data-aos-delay="300">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Project Overview</h2>
            </div>
            <div class="section-content">
                <p>The Sketch-to-Image & Inpainting Tool is a local desktop application built with Tkinter that integrates Stable Diffusion XL and ControlNet-Scribble. It converts hand-drawn sketches into high-quality photorealistic images and enables precise inpainting using custom brush masks. The entire pipeline runs on your GPU via Hugging Face Diffusersâ€”ensuring fast, offline generation with complete data privacy.</p>
                <br>
                <br>
                <h3>Key Capabilities</h3>
                <ul class="feature-list">
                    <li>Sketch-to-image generation using SDXL + ControlNet (scribble-based)</li>
                    <li>Brush-based inpainting on generated images</li>
                    <li>Real-time inference with multi-threaded preview updates</li>
                    <li>Prompt customization for subject, design features, and environment</li>
                    <li>Adjustable brush size, eraser toggle, and undo functionality</li>
                    <li>One-click image export with JPEG/PNG support</li>
                </ul>
            </div>
        </div>
    </section>
    <!-- Workflow Section -->
    <section id="workflow" class="project-section bg-light">
        <div class="container">
            <div class="section-header" data-aos="fade-up" data-aos-delay="200">
                <h2 class="section-title">Generation Workflow</h2>
            </div>
            <div class="section-content two-column">
                <div class="workflow-images">
                    <div class="workflow-image" data-aos="fade-up" data-aos-delay="200">
<img src="../gifs/sd1.gif" alt="Sketch Input Processing" class="feature-image lazy-image" />                    </div>
                    <div class="workflow-image" data-aos="fade-up" data-aos-delay="300">
<img src="../gifs/sd2.gif" alt="ControlNet Processing" class="feature-image lazy-image" />                    </div>
                </div>
                <div class="workflow-steps">
                    <div class="workflow-step" data-aos="fade-up" data-aos-delay="200">
                        <h3>1. Sketch Drawing & Pre-processing</h3>
                        <p>You sketch directly on the Tkinter canvas using adjustable brush tools. The sketch is saved as a PIL image, resized to 512Ã—512, and converted into an inverted grayscale control map for ControlNet inputâ€”no extra edge-detection required.</p>
                    </div>
                    <div class="workflow-step" data-aos="fade-up" data-aos-delay="300">
                        <h3>2. ControlNet-Scribble Conditioning</h3>
                        <p>The ControlNet model interprets the control map to guide structure-aware generation. The conditioning strength is preconfigured, and generation is tuned for sketch-based inputs using `guess_mode` and dynamic thresholding.</p>
                    </div>
                    <div class="workflow-step" data-aos="fade-up" data-aos-delay="400">
                        <h3>3. SDXL Image Generation</h3>
                        <p>User-defined prompts (subject, style, environment) are combined with tuned negative prompts and passed to `StableDiffusionXLControlNetPipeline`. The model then renders a photorealistic image based on sketch and guidance inputs.</p>
                    </div>
                    <div class="workflow-step" data-aos="fade-up" data-aos-delay="500">
                        <h3>4. Inpainting & Export</h3>
                        <p>Activate Inpainting Mode to paint red mask areas over a generated image. `AutoPipelineForInpainting` selectively regenerates those regions. Results are composited with the base image, previewed in real time, and saved in JPEG/PNG format.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Features Section -->
    <section id="features" class="project-section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Advanced Features</h2>
            </div>
            <div class="features-grid">
                <div class="feature-card" data-aos="fade-up">
                    <div class="feature-icon">
                        <i class="fas fa-paint-brush"></i>
                    </div>
                    <h3>Sketch-to-Image</h3>
                    <p>Convert rough lines on the Tkinter canvas into photorealistic renders using SDXL + ControlNet-Scribble, faithfully preserving your original strokes.</p>
                </div>
                <div class="feature-card" data-aos="fade-up" data-aos-delay="100">
                    <div class="feature-icon">
                        <i class="fas fa-sliders-h"></i>
                    </div>
                    <h3>ControlNet-Scribble Guidance</h3>
                    <p>Uses the xinsir/controlnet-scribble-sdxl model to interpret sketch structure. Conditioning strength is preset for natural control with `guess_mode` and dynamic thresholding.</p>
                </div>
                <div class="feature-card" data-aos="fade-up" data-aos-delay="200">
                    <div class="feature-icon">
                        <i class="fas fa-magic"></i>
                    </div>
                    <h3>Interactive Inpainting</h3>
                    <p>Draw red masks over areas to regenerate using SDXLâ€™s inpainting model. Masked regions are selectively updated and seamlessly blended with the original image.</p>
                </div>
                <div class="feature-card" data-aos="fade-up" data-aos-delay="300">
                    <div class="feature-icon">
                        <i class="fas fa-cogs"></i>
                    </div>
                    <h3>Prompt-Driven Styling</h3>
                    <p>Input fields for subject, design elements, environment, and inpainting prompts enable flexible image generation without relying on separate style models.</p>
                </div>
                <div class="feature-card" data-aos="fade-up" data-aos-delay="400">
                    <div class="feature-icon">
                        <i class="fas fa-layer-group"></i>
                    </div>
                    <h3>Brush & Canvas Control</h3>
                    <p>Adjust brush size, toggle eraser, and undo strokes instantly. Canvas supports real-time sketching, masking, and automatic preview after each stroke.</p>
                </div>
                <div class="feature-card" data-aos="fade-up" data-aos-delay="500">
                    <div class="feature-icon">
                        <i class="fas fa-download"></i>
                    </div>
                    <h3>Offline Export</h3>
                    <p>Save generated or inpainted outputs locally as JPEG or PNG files. Fully offlineâ€”no cloud upload or third-party dependencies required.</p>
                </div>
            </div>
        </div>
    </section>
    <!-- Demo Gallery Section -->
    <section id="demo" class="project-section bg-light">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title">Generation Examples</h2>
                <p>Explore various examples of sketch-to-image transformations pre-tuned on a architecture-focused generation.</p>
                <p><strong>Note: These examples are pre-tuned on a architecture-focused generation, The model can be pre-tuned on any domain.</strong> </p>
            </div>
            <div class="demo-gallery">
                <div class="demo-item" data-aos="fade-up" data-aos-delay="50">
                    <div class="demo-image">
<img src="../images/3.jpeg" alt="Architectural Generation" / class="lazy-image">                    </div>
                </div>
                <div class="demo-item" data-aos="fade-up" data-aos-delay="50">
                    <div class="demo-image">
<img src="../images/6.jpeg" alt="Character Design" / class="lazy-image">                    </div>
                </div>
                <div class="demo-item" data-aos="fade-up" data-aos-delay="50">
                    <div class="demo-image">
<img src="../images/image5.png" alt="Product Design" / class="lazy-image">                    </div>
                </div>
                <div class="demo-item" data-aos="fade-up" data-aos-delay="50">
                    <div class="demo-image">
<img src="../images/output2.png" alt="Landscape Generation" / class="lazy-image">                    </div>
                </div>
                <div class="demo-item" data-aos="fade-up" data-aos-delay="50">
                    <div class="demo-image">
<img src="../images/image.3.png" alt="Fashion Design" / class="lazy-image">                    </div>
                </div>
                <br>
                <div class="video-wrapper" style="margin-top: 1rem; text-align: center;" data-aos="fade-up" data-aos-delay="100">
										<iframe
											src="https://player.vimeo.com/video/1071282422"
											class="responsive-iframe"
											frameborder="0"
											allow="autoplay; fullscreen; picture-in-picture"
											allowfullscreen
										>
                                        </iframe>
				</div>
                </div>
            </div>
        </div>
    </section>
    <!-- Tools & Technologies Section -->
    <section id="tools" class="project-section">
        <div class="container">
            <div class="section-header">
                <h2 class="section-title" data-aos="fade-up" data-aos-delay="200">Tools & Technologies</h2>
            </div>
            <div class="section-content">
                <div class="tools-table">
                    <div class="table-responsive" data-aos="fade-up" data-aos-delay="300">
                        <table>
                            <thead>
                                <tr>
                                    <th>Category</th>
                                    <th>Technology</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><strong>Model</strong></td>
                                    <td>Stable Diffusion XL â€” RealVisXL V4.0 Lightning (via Hugging Face)</td>
                                </tr>
                                <tr>
                                    <td><strong>Control Networks</strong></td>
                                    <td>xinsir/controlnet-scribble-sdxl-1.0 for sketch-guided generation</td>
                                </tr>
                                <tr>
                                    <td><strong>Framework</strong></td>
                                    <td>Hugging Face Diffusers with PyTorch (FP16 + CUDA)</td>
                                </tr>
                                <tr>
                                    <td><strong>Image Processing</strong></td>
                                    <td>Pillow (PIL) for sketch capture, inpainting masks, and output export</td>
                                </tr>
                                <tr>
                                    <td><strong>Interface</strong></td>
                                    <td>Tkinter GUI with live drawing, masking, sliders, and prompt inputs</td>
                                </tr>
                                <tr>
                                    <td><strong>Acceleration</strong></td>
                                    <td>Local GPU (torch.float16 inference, DDIM scheduler)</td>
                                </tr>
                                <tr>
                                    <td><strong>Model Hub</strong></td>
                                    <td>Pretrained models loaded from Hugging Face Hub</td>
                                </tr>
                                <tr>
                                    <td><strong>Deployment</strong></td>
                                    <td>Fully offline Python desktop app (no web server required)</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-logo">
                    <span>Y_W_SONG</span>
                </div>
                <div class="footer-social">
                    <a href="https://github.com/Userdflt" aria-label="GitHub">
                        <i class="fab fa-github"></i>
                    </a>
                    <a href="https://www.linkedin.com/in/young-woo-song-145488217/" aria-label="LinkedIn">
                        <i class="fab fa-linkedin-in"></i>
                    </a>
                    <a href="https://youngwoosongcv.notion.site/Young-Woo-Song-1c964ba2209280bb954ad884c1a11b0f" aria-label="Notion">
                        <i class="fas fa-file-alt"></i>
                    </a>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 Young Woo Song. All rights reserved.</p>
            </div>
        </div>
    </footer>
    <!-- Scripts -->
    <script src="../js/project-scripts.js"></script>
    <script>
        // E-ink style page initialization
        document.addEventListener("DOMContentLoaded", function() {
            console.log("ðŸ“– Project Page - E-ink Style Loading...");
            setTimeout(() => {
                document.body.classList.add("e-ink-transition");
                setTimeout(() => {
                    document.body.classList.remove("e-ink-transition");
                    console.log("ðŸ“š Project Page Ready");
                }, 500);
            }, 100);
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Initialize AOS
            if (typeof AOS !== 'undefined') {
            }
            // Mobile Menu Toggle
            const mobileToggle = document.querySelector('.mobile-toggle');
            const mainNav = document.querySelector('.main-nav');
            if (mobileToggle) {
                mobileToggle.addEventListener('click', function() {
                    this.classList.toggle('active');
                    mainNav.classList.toggle('active');
                    document.body.style.overflow = mainNav.classList.contains('active') ? 'hidden' : '';
                });
            }
            // Close mobile menu when clicking on a link
            const navLinks = document.querySelectorAll('.nav-links a');
            navLinks.forEach(link => {
                link.addEventListener('click', () => {
                    if (mobileToggle) {
                        mobileToggle.classList.remove('active');
                        mainNav.classList.remove('active');
                        document.body.style.overflow = '';
                    }
                });
            });
            // Header Scroll Effect
            const header = document.querySelector('.header');
            function handleScroll() {
                if (window.scrollY > 50) {
                    header.classList.add('scrolled');
                } else {
                    header.classList.remove('scrolled');
                }
            }
            window.addEventListener('scroll', handleScroll);
            handleScroll();
            // Smooth scrolling for anchor links
            const anchorLinks = document.querySelectorAll('a[href^="#"]');
            anchorLinks.forEach(link => {
                link.addEventListener('click', function(e) {
                    e.preventDefault();
                    const targetId = this.getAttribute('href');
                    const targetElement = document.querySelector(targetId);
                    if (targetElement) {
                        const headerHeight = header.offsetHeight;
                        const targetPosition = targetElement.offsetTop - headerHeight;
                        window.scrollTo({
                            top: targetPosition,
                            behavior: 'smooth'
                        });
                    }
                });
            });
            // Demo gallery hover effects
            const demoItems = document.querySelectorAll('.demo-item');
            demoItems.forEach(item => {
                item.addEventListener('mouseenter', function() {
                    this.style.transform = 'translateY(-8px) scale(1.02)';
                });
                item.addEventListener('mouseleave', function() {
                    this.style.transform = 'translateY(0) scale(1)';
                });
            });
            console.log('ðŸŽ¨ Stable Diffusion page initialized successfully!');
        });
    </script>
</body>
</html>
